{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd D:\\Project\\Toolkit_for_Preprocessing_MXH\\VSMEC_chunking\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# clear gpu memory using torch\n",
    "torch.cuda.empty_cache()\n",
    "# clear output\n",
    "clear_output()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = (r\"Data\\train.csv\")\n",
    "dev_path = (r\"Data\\dev.csv\")\n",
    "test_path = (r\"Data\\test.csv\")\n",
    "model_name = 'vinai/phobert-base'\n",
    "test_index = 20 # default None value\n",
    "batch_size = 32\n",
    "max_len = 128\n",
    "lr = 5e-6\n",
    "epochs = 2\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 14 samples\n",
      "Test set: 3 samples\n",
      "Development set: 3 samples\n"
     ]
    }
   ],
   "source": [
    "from Code.Dataset import split_path, create_dataloader\n",
    "\n",
    "if test_index != None and test_index > 3:\n",
    "    # Load the data\n",
    "    train_path, dev_path, test_path = split_path(test_path, test_index, train_path, dev_path, test_path)\n",
    "elif test_index != None: \n",
    "    print(\"Test index out of range. Please provide a valid interger index greater than 3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(64001, 768, padding_idx=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer, AutoModel\n",
    ")\n",
    "\n",
    "\n",
    "classes = ['Anger','Disgust','Enjoyment','Fear','Other','Sadness','Surprise']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "embedding_model = AutoModel.from_pretrained(model_name)\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(classes)  # Number of classes\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "# Adjust the token embeddings size if needed\n",
    "embedding_model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, embedding_model, classification_model, dropout_rate=0.1):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        # self.classification_head = classification_model\n",
    "        self.classification_head = nn.Linear(768, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Check for NaN values in input tensors\n",
    "        if torch.isnan(input_ids).any() or torch.isinf(input_ids).any():\n",
    "            raise ValueError(\"Input IDs contain NaN or Inf values.\")\n",
    "        if torch.isnan(attention_mask).any() or torch.isinf(attention_mask).any():\n",
    "            raise ValueError(\"Attention mask contains NaN or Inf values.\")\n",
    "\n",
    "        # Flatten inputs\n",
    "        batch_size = input_ids.size(0)\n",
    "        max_length = input_ids.size(1)\n",
    "        input_ids_flat = input_ids.view(-1, input_ids.size(-1))\n",
    "        attention_mask_flat = attention_mask.view(-1, attention_mask.size(-1))\n",
    "\n",
    "        \n",
    "        print(\"input_ids_flat: \", input_ids_flat.shape)\n",
    "        print(\"attention_mask_flat: \", attention_mask_flat.shape)\n",
    "        # Get embeddings\n",
    "        \n",
    "        # Ensure token_type_ids are passed\n",
    "        token_type_ids = torch.zeros_like(input_ids_flat)  # Default to zeros if not provided\n",
    "\n",
    "#         outputs = self.embedding_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "\n",
    "        if torch.isnan(input_ids_flat).any() or torch.isinf(input_ids_flat).any():\n",
    "            raise ValueError(\"Input IDs contain NaN or Inf values.\")\n",
    "        if torch.isnan(attention_mask_flat).any() or torch.isinf(attention_mask_flat).any():\n",
    "            raise ValueError(\"Attention mask contains NaN or Inf values.\")\n",
    "\n",
    "        outputs = self.embedding_model(input_ids=input_ids_flat, attention_mask=attention_mask_flat, token_type_ids=token_type_ids)\n",
    "        \n",
    "\n",
    "\n",
    "        # Check the type and contents of outputs\n",
    "        print(\"Outputs from embedding model:\", outputs)\n",
    "\n",
    "        # Ensure outputs is in the expected format\n",
    "        if isinstance(outputs, tuple):\n",
    "            last_hidden_state = outputs[0]  # The first element is often last_hidden_state\n",
    "        else:\n",
    "            last_hidden_state = outputs.last_hidden_state if hasattr(outputs, 'last_hidden_state') else None\n",
    "\n",
    "        # Check if last_hidden_state is None\n",
    "        if last_hidden_state is None:\n",
    "            print(\"last_hidden_state is None. Check the output structure of the embedding model.\")\n",
    "\n",
    "        # Debugging output for last_hidden_state\n",
    "        print(\"Last hidden state shape:\", last_hidden_state.shape)\n",
    "\n",
    "        # Check for NaNs in last_hidden_state\n",
    "        if torch.isnan(last_hidden_state).any():\n",
    "            print(\"last_hidden_state values:\", last_hidden_state)\n",
    "            print(\"last_hidden_state contains NaN values.\")\n",
    "\n",
    "        if outputs is None:\n",
    "            print(\"Embedding model output is None.\")\n",
    "        # Mean pooling\n",
    "        print(\"last_hidden_state: \", last_hidden_state.shape)\n",
    "        \n",
    "        \n",
    "        if torch.isnan(last_hidden_state).any():\n",
    "            print(\"last_hidden_state contain NaN values. \")\n",
    "        pooled_embeddings = last_hidden_state.mean(dim=1)\n",
    "        if torch.isnan(pooled_embeddings).any():\n",
    "            print(\"Pooled embeddings contain NaN values.\")\n",
    "        pooled_embeddings = pooled_embeddings.view(batch_size, max_length, 768).mean(dim=1)\n",
    "        print(\"pooled_embeddings: \", pooled_embeddings.shape)\n",
    "        \n",
    "        \n",
    "        if torch.isnan(pooled_embeddings).any():\n",
    "            print(\"Pooled embeddings contain NaN values. 1\")\n",
    "\n",
    "        pooled_output = self.dropout(pooled_embeddings)\n",
    "        print(\"pooled_output: \", pooled_output.shape)\n",
    "\n",
    "        if torch.isnan(pooled_output).any():\n",
    "            print(\"Pooled output contains NaN values after dropout.\")\n",
    "            \n",
    "        \n",
    "\n",
    "        # Logits computation\n",
    "        logits = self.classification_head(pooled_output)\n",
    "#         if logits is None:\n",
    "#             raise ValueError(\"Logits are None after classification head.\")\n",
    "\n",
    "        print(\"Logits: \", logits)\n",
    "\n",
    "        logits = torch.sigmoid(logits)  # Adjust if necessary for your task\n",
    "        print(\"Logits: \", logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Input IDs: torch.Size([2, 4, 128])\n",
      "Attention Mask: torch.Size([2, 4, 128])\n",
      "Labels: torch.Size([2, 7])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = create_dataloader(train_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)\n",
    "dev_dataloader = create_dataloader(dev_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)\n",
    "test_dataloader = create_dataloader(test_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)\n",
    "\n",
    "# Get the first batch of data from the DataLoader\n",
    "first_batch = next(iter(test_dataloader))\n",
    "\n",
    "# Access input_ids, attention_mask, and labels\n",
    "input_ids = first_batch['input_ids']\n",
    "attention_mask = first_batch['attention_mask']\n",
    "labels = first_batch['label']\n",
    "\n",
    "# Print to check\n",
    "print(f\"Input IDs: {input_ids.size()}\")\n",
    "print(f\"Attention Mask: {attention_mask.size()}\")\n",
    "print(f\"Labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "from Code.Model import setup_model, train, test , MultiTaskModel\n",
    "\n",
    "model, criterion, optimizer, device, num_epochs = setup_model(\n",
    "    model_class = MultiTaskModel, \n",
    "    embedding_model = embedding_model, \n",
    "    classification_model = classification_model,\n",
    "    lr=5e-6,\n",
    "    weight_decay=1e-5,\n",
    "    num_epochs=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6940\n",
      "Validation Loss: 0.6590\n",
      "Macro F1-Score: 0.1429\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6695\n",
      "Validation Loss: 0.6478\n",
      "Macro F1-Score: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Assuming you've set up the model, dataloaders, criterion, and optimizer\n",
    "train(model, train_dataloader, dev_dataloader, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions, true_labels = test(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "4.44.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training set: 35 samples\n",
      "Test set: 7 samples\n",
      "Development set: 8 samples\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Input IDs: torch.Size([6, 4, 128])\n",
      "Attention Mask: torch.Size([6, 4, 128])\n",
      "Labels: torch.Size([6, 7])\n",
      "Epoch: 1\n",
      "Training Loss: 0.9010\n",
      "Validation Loss: 0.8919\n",
      "Macro F1-Score: 0.0000\n",
      "Epoch: 2\n",
      "Training Loss: 0.8865\n",
      "Validation Loss: 0.8701\n",
      "Macro F1-Score: 0.0000\n",
      "Macro F1 Score: 0.4615\n",
      "Test results saved to test_results.json\n",
      "Model saved to output\\trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Training:  20%|██        | 1/5 [00:22<01:31, 22.77s/it]\n",
      "Training:  40%|████      | 2/5 [00:43<01:03, 21.31s/it]\n",
      "Training:  60%|██████    | 3/5 [01:03<00:41, 20.75s/it]\n",
      "Training:  80%|████████  | 4/5 [01:23<00:20, 20.49s/it]\n",
      "Training: 100%|██████████| 5/5 [01:27<00:00, 14.57s/it]\n",
      "                                                       \n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "                                                         \n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Training:  20%|██        | 1/5 [00:20<01:21, 20.33s/it]\n",
      "Training:  40%|████      | 2/5 [00:40<01:00, 20.18s/it]\n",
      "Training:  60%|██████    | 3/5 [01:00<00:40, 20.19s/it]\n",
      "Training:  80%|████████  | 4/5 [01:20<00:20, 20.03s/it]\n",
      "Training: 100%|██████████| 5/5 [01:24<00:00, 14.25s/it]\n",
      "                                                       \n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "                                                         \n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "Testing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Testing: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model \"vinai/phobert-base\" --train_path \"Data\\train.csv\" --dev_path \"Data\\dev.csv\" --test_path \"Data\\test.csv\" --batch_size 8 --max_len 128 --lr 5e-6 --num_epochs 2 --output_json \"test_results.json\" --output_dir \"output\" --test_index 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training set: 35 samples\n",
      "Test set: 7 samples\n",
      "Development set: 8 samples\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Columns: Index(['index', 'Emotion', 'Text', 'Tag', 'sentence_id'], dtype='object')\n",
      "Input IDs: torch.Size([6, 4, 128])\n",
      "Attention Mask: torch.Size([6, 4, 128])\n",
      "Labels: torch.Size([6, 7])\n",
      "Epoch: 1\n",
      "Training Loss: 0.8970\n",
      "Validation Loss: 0.8906\n",
      "Macro F1-Score: 0.0765\n",
      "Epoch: 2\n",
      "Training Loss: 0.8882\n",
      "Validation Loss: 0.8775\n",
      "Macro F1-Score: 0.0000\n",
      "Macro F1 Score: 0.4545\n",
      "Test results saved to test_results.json\n",
      "Model saved to output\\trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Training:  20%|██        | 1/5 [00:26<01:44, 26.25s/it]\n",
      "Training:  40%|████      | 2/5 [00:46<01:08, 22.70s/it]\n",
      "Training:  60%|██████    | 3/5 [01:06<00:43, 21.71s/it]\n",
      "Training:  80%|████████  | 4/5 [01:26<00:20, 20.95s/it]\n",
      "Training: 100%|██████████| 5/5 [01:31<00:00, 14.95s/it]\n",
      "                                                       \n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "                                                         \n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Training:  20%|██        | 1/5 [00:21<01:26, 21.57s/it]\n",
      "Training:  40%|████      | 2/5 [00:41<01:01, 20.53s/it]\n",
      "Training:  60%|██████    | 3/5 [01:01<00:40, 20.23s/it]\n",
      "Training:  80%|████████  | 4/5 [01:21<00:20, 20.14s/it]\n",
      "Training: 100%|██████████| 5/5 [01:25<00:00, 14.43s/it]\n",
      "                                                       \n",
      "\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "                                                         \n",
      "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "Testing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Testing: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Testing: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model \"vinai/phobert-base\" --train_path \"Data\\train.csv\" --dev_path \"Data\\dev.csv\" --test_path \"Data\\test.csv\" --batch_size 8 --max_len 128 --lr 5e-6 --num_epochs 2 --output_json \"test_results.json\" --output_dir \"output\" --test_index 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
